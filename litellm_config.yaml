model_list:
  # - model_name: gpt-3.5-turbo ### RECEIVED MODEL NAME ###
  #   litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
  #     model: azure/gpt-turbo-small-eu ### MODEL NAME sent to `litellm.completion()` ###
  #     api_base: https://my-endpoint-europe-berri-992.openai.azure.com/
  #     api_key: "os.environ/AZURE_API_KEY_EU" # does os.getenv("AZURE_API_KEY_EU")
  #     rpm: 6      # [OPTIONAL] Rate limit for this deployment: in requests per minute (rpm)
  # - model_name: bedrock-claude-v1 
  #   litellm_params:
  #     model: bedrock/anthropic.claude-instant-v1
  # - model_name: azure-gpt-3.5
  #   litellm_params:
  #     model: azure/<your-azure-model-deployment>
  #     api_base: os.environ/AZURE_API_BASE # runs os.getenv("AZURE_API_BASE")
  #     api_key: os.environ/AZURE_API_KEY # runs os.getenv("AZURE_API_KEY")
  #     api_version: "2023-07-01-preview"
  # - model_name: gpt-3.5-turbo
  #   litellm_params:
  #     model: azure/gpt-turbo-small-ca
  #     api_base: https://my-endpoint-canada-berri992.openai.azure.com/
  #     api_key: "os.environ/AZURE_API_KEY_CA"
  #     rpm: 6
  # - model_name: anthropic-claude
  #   litellm_params: 
  #     model: bedrock/anthropic.claude-instant-v1
  #     ### [OPTIONAL] SET AWS REGION ###
  #     aws_region_name: us-east-1
  # - model_name: vllm-models
  #   litellm_params:
  #     model: openai/facebook/opt-125m # the `openai/` prefix tells litellm it's openai compatible
  #     api_base: http://0.0.0.0:4000/v1
  #     api_key: none
  #     rpm: 1440
  #   model_info: 
  #     version: 2
  # - model_name: gpt-4-team1
  #   litellm_params: # params for litellm.completion() - https://docs.litellm.ai/docs/completion/input#input---request-body
  #     model: azure/chatgpt-v-2
  #     api_base: https://openai-gpt-4-test-v-1.openai.azure.com/
  #     api_version: "2023-05-15"
  #     azure_ad_token: eyJ0eXAiOiJ
  #     seed: 12
  #     max_tokens: 20
  # - model_name: gpt-4-team2
  #   litellm_params:
  #     model: azure/gpt-4
  #     api_key: sk-123
  #     api_base: https://openai-gpt-4-test-v-2.openai.azure.com/
  #     temperature: 0.2
  # - model_name: openai-gpt-3.5
  #   litellm_params:
  #     model: openai/gpt-3.5-turbo
  #     extra_headers: {"AI-Resource Group": "ishaan-resource"}
  #     api_key: sk-123
  #     organization: org-ikDc4ex8NB
  #     temperature: 0.2
  - model_name: mistral-7b
    litellm_params:
      model: ollama/mistral
      api_base: http://100.94.136.15://11434 #your_ollama_api_base      
  
  # # Use this if you want to make requests to `claude-3-haiku-20240307`,`claude-3-opus-20240229`,`claude-2.1` without defining them on the config.yaml
  # # Default models
  # # Works for ALL Providers and needs the default provider credentials in .env
  # - model_name: "*" 
  #   litellm_params:
  #     model: "*"

litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
  drop_params: True
  success_callback: ["langfuse"] # OPTIONAL - if you want to start sending LLM Logs to Langfuse. Make sure to set `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY` in your env

general_settings: 
  master_key: sk-1234 # [OPTIONAL] Only use this if you to require all calls to contain this key (Authorization: Bearer sk-1234)
  alerting: ["slack"] # [OPTIONAL] If you want Slack Alerts for Hanging LLM requests, Slow llm responses, Budget Alerts. Make sure to set `SLACK_WEBHOOK_URL` in your env
